{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/IBM-EPBL/IBM-Project-37207-1660301541/blob/main/Image%20processing/Apply%20ImageDataGenerator%20Functionality.ipynb","timestamp":1667193214219}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!git clone https://github.com/IBM-EPBL/IBM-Project-321-1658278283.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BXkfQzVPvJkl","executionInfo":{"status":"ok","timestamp":1668272890592,"user_tz":-330,"elapsed":2140,"user":{"displayName":"Sath ish","userId":"05195963178260667618"}},"outputId":"99d2e65a-dc0e-466d-b714-d468f759604f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'IBM-Project-321-1658278283'...\n","remote: Enumerating objects: 19310, done.\u001b[K\n","remote: Total 19310 (delta 0), reused 0 (delta 0), pack-reused 19310\u001b[K\n","Receiving objects: 100% (19310/19310), 15.40 MiB | 30.57 MiB/s, done.\n","Resolving deltas: 100% (1217/1217), done.\n"]}]},{"cell_type":"code","source":["!pip install geopandas"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cxk0Nklbwr4_","executionInfo":{"status":"ok","timestamp":1668272903645,"user_tz":-330,"elapsed":10692,"user":{"displayName":"Sath ish","userId":"05195963178260667618"}},"outputId":"bbe614ca-bb7f-410f-fee7-527e7b9bb0e7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting geopandas\n","  Downloading geopandas-0.10.2-py2.py3-none-any.whl (1.0 MB)\n","\u001b[K     |████████████████████████████████| 1.0 MB 7.6 MB/s \n","\u001b[?25hCollecting pyproj>=2.2.0\n","  Downloading pyproj-3.2.1-cp37-cp37m-manylinux2010_x86_64.whl (6.3 MB)\n","\u001b[K     |████████████████████████████████| 6.3 MB 39.7 MB/s \n","\u001b[?25hRequirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.3.5)\n","Collecting fiona>=1.8\n","  Downloading Fiona-1.8.22-cp37-cp37m-manylinux2014_x86_64.whl (16.7 MB)\n","\u001b[K     |████████████████████████████████| 16.7 MB 725 kB/s \n","\u001b[?25hRequirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.5.post1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (57.4.0)\n","Collecting cligj>=0.5\n","  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n","Collecting munch\n","  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n","Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (22.1.0)\n","Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n","Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n","Collecting click-plugins>=1.0\n","  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2022.9.24)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (1.21.6)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2.8.2)\n","Installing collected packages: munch, cligj, click-plugins, pyproj, fiona, geopandas\n","Successfully installed click-plugins-1.1.1 cligj-0.7.2 fiona-1.8.22 geopandas-0.10.2 munch-2.5.0 pyproj-3.2.1\n"]}]},{"cell_type":"code","source":["from keras.preprocessing.image import ImageDataGenerator\n","train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n","test_datagen=ImageDataGenerator(rescale=1./255)"],"metadata":{"id":"3N9t6zEw0MDu","executionInfo":{"status":"ok","timestamp":1668272964624,"user_tz":-330,"elapsed":3994,"user":{"displayName":"Sath ish","userId":"05195963178260667618"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["x_train = train_datagen.flow_from_directory('/content/IBM-Project-321-1658278283/Data Collection/Train_Set',target_size=(64,64),batch_size=300,class_mode='categorical',color_mode=\"grayscale\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fWiB_11w0Uk_","executionInfo":{"status":"ok","timestamp":1668273031104,"user_tz":-330,"elapsed":396,"user":{"displayName":"Sath ish","userId":"05195963178260667618"}},"outputId":"9618018c-5b6f-4dad-9aad-014c882c3910"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 14728 images belonging to 9 classes.\n"]}]},{"cell_type":"markdown","source":["**Real-Time Communication System Powered By AI For Specially Abled**"],"metadata":{"id":"iyXef0Kk1ghL"}},{"cell_type":"markdown","source":["Loading the Dataset & Image Data Generation"],"metadata":{"id":"jTOGUIfG1w0S"}},{"cell_type":"code","source":["x_test = test_datagen.flow_from_directory('/content/IBM-Project-321-1658278283/Data Collection/Test_set',target_size=(64,64),batch_size=300,class_mode='categorical',color_mode=\"grayscale\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4028fNOz0nnN","executionInfo":{"status":"ok","timestamp":1668273135287,"user_tz":-330,"elapsed":424,"user":{"displayName":"Sath ish","userId":"05195963178260667618"}},"outputId":"01a845d4-ebde-429f-aab3-aa13ccfbb542"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2250 images belonging to 9 classes.\n"]}]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Convolution2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Dropout\n","from keras.layers import Flatten"],"metadata":{"id":"hENrq9luV5CV","executionInfo":{"status":"ok","timestamp":1668273161595,"user_tz":-330,"elapsed":574,"user":{"displayName":"Sath ish","userId":"05195963178260667618"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["model = Sequential()"],"metadata":{"id":"_Xog4wM-WHQL","executionInfo":{"status":"ok","timestamp":1668273180622,"user_tz":-330,"elapsed":409,"user":{"displayName":"Sath ish","userId":"05195963178260667618"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["model.add(Convolution2D(32,(3,3),input_shape=(64,64,1), activation='relu'))\n","#no. of feature detectors, size of feature detector, image size, activation function"],"metadata":{"id":"IxBznrvkXOiQ","executionInfo":{"status":"ok","timestamp":1668273202994,"user_tz":-330,"elapsed":675,"user":{"displayName":"Sath ish","userId":"05195963178260667618"}}},"execution_count":10,"outputs":[]}]}