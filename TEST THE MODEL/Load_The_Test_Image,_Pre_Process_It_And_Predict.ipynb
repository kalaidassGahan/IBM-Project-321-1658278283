{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/IBM-EPBL/IBM-Project-37207-1660301541/blob/main/Test%20The%20Model/Load_The_Test_Image%2C_Pre_Process_It_And_Predict.ipynb","timestamp":1667193791884}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"yhrkzc9ZpmOU"},"outputs":[],"source":["from keras.preprocessing.image import ImageDataGenerator\n","train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n","test_datagen=ImageDataGenerator(rescale=1./255)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fxzt85D8oP9-","executionInfo":{"status":"ok","timestamp":1668336990630,"user_tz":-330,"elapsed":66878,"user":{"displayName":"Sath ish","userId":"05195963178260667618"}},"outputId":"1efe3144-75a0-4985-d317-2470163e5498"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["x_train = train_datagen.flow_from_directory('/content/drive/MyDrive/IBM-Project-321-1658278283-main/Data Collection/Train_Set',target_size=(64,64),batch_size=300,class_mode='categorical',color_mode=\"grayscale\")"],"metadata":{"id":"911jlfgkNnqq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0c431c63-2028-4091-907f-35bc9e0b41ea","executionInfo":{"status":"ok","timestamp":1668337030156,"user_tz":-330,"elapsed":15018,"user":{"displayName":"Sath ish","userId":"05195963178260667618"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 14928 images belonging to 9 classes.\n"]}]},{"cell_type":"code","source":["x_test = test_datagen.flow_from_directory('/content/drive/MyDrive/IBM-Project-321-1658278283-main/Data Collection/Test_set',target_size=(64,64),batch_size=300,class_mode='categorical',color_mode=\"grayscale\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0jQeqRgJQ_k3","outputId":"230c55bc-8240-4d0c-e37c-784fb61d482e","executionInfo":{"status":"ok","timestamp":1668337033248,"user_tz":-330,"elapsed":3116,"user":{"displayName":"Sath ish","userId":"05195963178260667618"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2250 images belonging to 9 classes.\n"]}]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Convolution2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Dropout\n","from keras.layers import Flatten"],"metadata":{"id":"hENrq9luV5CV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()"],"metadata":{"id":"_Xog4wM-WHQL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.add(Convolution2D(32,(3,3),input_shape=(64,64,1), activation='relu'))\n","#no. of feature detectors, size of feature detector, image size, activation function"],"metadata":{"id":"IxBznrvkXOiQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.add(MaxPooling2D(pool_size=(2,2)))"],"metadata":{"id":"m9i6nyiiYAzH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.add(Flatten())"],"metadata":{"id":"YrEJW7pAYFA4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.add(Dense(units=512, activation = 'relu'))"],"metadata":{"id":"qIvMupXlYg8d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.add(Dense(units=9,  activation = 'softmax'))"],"metadata":{"id":"BSaehFfcY4iz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"],"metadata":{"id":"Dq7W6q62Y9RC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.fit_generator(x_train,steps_per_epoch=24,epochs=10,validation_data = x_test, validation_steps= 40)\n","#steps_per_epoch = no. of train images//batch size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T530ZkC6ZSOk","outputId":"7f4acc10-8c0b-47e9-c403-b609e1f7eae5","executionInfo":{"status":"ok","timestamp":1668339868448,"user_tz":-330,"elapsed":186192,"user":{"displayName":"Sath ish","userId":"05195963178260667618"}}},"execution_count":13,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  \"\"\"Entry point for launching an IPython kernel.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","24/24 [==============================] - ETA: 0s - loss: 0.9245 - accuracy: 0.7083 "]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 40 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1258s 53s/step - loss: 0.9245 - accuracy: 0.7083 - val_loss: 0.3802 - val_accuracy: 0.9169\n","Epoch 2/10\n","24/24 [==============================] - 501s 21s/step - loss: 0.2444 - accuracy: 0.9369\n","Epoch 3/10\n","24/24 [==============================] - 278s 12s/step - loss: 0.1479 - accuracy: 0.9630\n","Epoch 4/10\n","24/24 [==============================] - 145s 6s/step - loss: 0.0861 - accuracy: 0.9793\n","Epoch 5/10\n","24/24 [==============================] - 93s 4s/step - loss: 0.0718 - accuracy: 0.9805\n","Epoch 6/10\n","24/24 [==============================] - 63s 3s/step - loss: 0.0603 - accuracy: 0.9839\n","Epoch 7/10\n","24/24 [==============================] - 52s 2s/step - loss: 0.0455 - accuracy: 0.9844\n","Epoch 8/10\n","24/24 [==============================] - 46s 2s/step - loss: 0.0408 - accuracy: 0.9883\n","Epoch 9/10\n","24/24 [==============================] - 46s 2s/step - loss: 0.0395 - accuracy: 0.9882\n","Epoch 10/10\n","24/24 [==============================] - 46s 2s/step - loss: 0.0384 - accuracy: 0.9893\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f4bd95ea390>"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["model.save('aslpng1.h5')"],"metadata":{"id":"tbD4YC8VZlIB","executionInfo":{"status":"ok","timestamp":1668339878455,"user_tz":-330,"elapsed":436,"user":{"displayName":"Sath ish","userId":"05195963178260667618"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["from keras.models import load_model\n","import numpy as np\n","import cv2"],"metadata":{"id":"wBCEfO5qd0Gj","executionInfo":{"status":"ok","timestamp":1668339879933,"user_tz":-330,"elapsed":662,"user":{"displayName":"Sath ish","userId":"05195963178260667618"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["model=load_model('aslpng1.h5')"],"metadata":{"id":"sZYDfTiuZmUU","executionInfo":{"status":"ok","timestamp":1668339881761,"user_tz":-330,"elapsed":1043,"user":{"displayName":"Sath ish","userId":"05195963178260667618"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["from skimage.transform import resize\n","def detect(frame):\n","  img = resize(frame,(64,64,1))\n","  img = np.expand_dims(img,axis=0)\n","  if(np.max(img)>1):\n","    img = img/255.0\n","  prediction = model.predict(img)\n","  print(prediction)\n","  prediction = np.argmax(prediction,axis=1)\n","  print(prediction)"],"metadata":{"id":"05vEcPg2bJfW","executionInfo":{"status":"ok","timestamp":1668339882348,"user_tz":-330,"elapsed":596,"user":{"displayName":"Sath ish","userId":"05195963178260667618"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["frame=cv2.imread('/content/Dataset/test_set/G/1.png')\n","data = detect(frame)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":345},"id":"bdi1cEHebj35","outputId":"14dece2c-f15d-441e-8884-56aa00b2e62c","executionInfo":{"status":"error","timestamp":1668339886679,"user_tz":-330,"elapsed":547,"user":{"displayName":"Sath ish","userId":"05195963178260667618"}}},"execution_count":18,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-6192f00c1c9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Dataset/test_set/G/1.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-17-9103b1fc61d4>\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(frame)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0moutput_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_ndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# append dimensions to input_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"LQ1_aUY3b1qJ"},"execution_count":null,"outputs":[]}]}